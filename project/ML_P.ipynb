{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"p1_emg.csv\")  # Replace with actual filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping (excluding 'rest')\n",
    "mapg = {\n",
    "    \"Thumb Extension\":0,\"index Extension\":1,\"Middle Extension\":2,\"Ring Extension\":3,\n",
    "    \"Pinky Extension\":4,\"Thumbs Up\":5,\"Right Angle\":6,\"Peace\":7,\"OK\":8,\"Horn\":9,\"Hang Loose\":10,\n",
    "    \"Power Grip\":11,\"Hand Open\":12,\"Wrist Extension\":13,\"Wrist Flexion\":14,\n",
    "    \"Ulnar deviation\":15,\"Radial Deviation\":16\n",
    "}\n",
    "\n",
    "df = df[df['label'] != 'rest']\n",
    "df['label'] = df['label'].map(mapg)\n",
    "\n",
    "# Normalize EMG features\n",
    "features = [col for col in df.columns if 'emg' in col]\n",
    "# Min-Max Scaling to [0, 1]\n",
    "min_vals = df[features].min()\n",
    "max_vals = df[features].max()\n",
    "df[features] = (df[features] - min_vals) / (max_vals - min_vals + 1e-8)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "window_size = 100  # adjust based on your data\n",
    "features = [col for col in df.columns if 'emg' in col]\n",
    "\n",
    "# Create clean, non-overlapping windows with consistent labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(df) - window_size + 1, window_size):\n",
    "    window = df.iloc[i:i+window_size]\n",
    "    label_set = window['label'].unique()\n",
    "    if len(label_set) == 1:  # Only keep windows with a single label\n",
    "        X.append(window[features].values.astype(np.float32))\n",
    "        y.append(label_set[0])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Dataset\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X)  # shape: (N, window, channels)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].permute(1, 0), self.y[idx]  # shape: (channels, window)\n",
    "\n",
    "dataset = EMGDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2916"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# CNN Model\n",
    "# class EMGCNN(nn.Module):\n",
    "#     def __init__(self, num_classes=17, num_channels=8):\n",
    "#         super(EMGCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(num_channels, 64, kernel_size=3)\n",
    "#         self.pool = nn.MaxPool1d(2)\n",
    "#         self.fc1 = nn.Linear(64 * ((window_size - 2) // 2), 100)\n",
    "#         self.fc2 = nn.Linear(100, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))  # (B, 64, L)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# Deep CNN Model\n",
    "class EMGCNN(nn.Module):\n",
    "    def __init__(self, num_classes=17, num_channels=8):\n",
    "        super(EMGCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_channels, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Calculate output size after convolutions and pooling\n",
    "        conv_output_size = window_size\n",
    "        for _ in range(3):  # 3 conv + pool layers\n",
    "            conv_output_size = conv_output_size // 2  # MaxPool1d halves it\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * conv_output_size, 128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # -> (B, 64, L/2)\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # -> (B, 128, L/4)\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # -> (B, 256, L/8)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Train setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EMGCNN(num_classes=len(mapg)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 92.15%\n",
      "Validation Accuracy: 66.78%\n",
      "Train Accuracy: 79.63%\n",
      "Validation Accuracy: 57.53%\n",
      "Train Accuracy: 90.78%\n",
      "Validation Accuracy: 65.41%\n",
      "Train Accuracy: 90.31%\n",
      "Validation Accuracy: 65.24%\n",
      "Train Accuracy: 92.62%\n",
      "Validation Accuracy: 67.81%\n",
      "Train Accuracy: 94.68%\n",
      "Validation Accuracy: 69.69%\n",
      "Train Accuracy: 82.72%\n",
      "Validation Accuracy: 56.68%\n",
      "Train Accuracy: 82.12%\n",
      "Validation Accuracy: 59.42%\n",
      "Train Accuracy: 93.01%\n",
      "Validation Accuracy: 70.55%\n",
      "Train Accuracy: 90.31%\n",
      "Validation Accuracy: 67.12%\n",
      "Train Accuracy: 82.80%\n",
      "Validation Accuracy: 61.82%\n",
      "Train Accuracy: 68.01%\n",
      "Validation Accuracy: 46.40%\n",
      "Train Accuracy: 89.19%\n",
      "Validation Accuracy: 62.67%\n",
      "Train Accuracy: 87.39%\n",
      "Validation Accuracy: 62.67%\n",
      "Train Accuracy: 87.91%\n",
      "Validation Accuracy: 61.82%\n",
      "Train Accuracy: 90.14%\n",
      "Validation Accuracy: 64.04%\n",
      "Train Accuracy: 89.62%\n",
      "Validation Accuracy: 62.84%\n",
      "Train Accuracy: 85.25%\n",
      "Validation Accuracy: 63.36%\n",
      "Train Accuracy: 90.69%\n",
      "Validation Accuracy: 65.24%\n",
      "Train Accuracy: 90.74%\n",
      "Validation Accuracy: 66.27%\n",
      "Train Accuracy: 84.86%\n",
      "Validation Accuracy: 57.36%\n",
      "Train Accuracy: 91.85%\n",
      "Validation Accuracy: 65.41%\n",
      "Train Accuracy: 93.95%\n",
      "Validation Accuracy: 65.92%\n",
      "Train Accuracy: 83.32%\n",
      "Validation Accuracy: 60.79%\n",
      "Train Accuracy: 93.83%\n",
      "Validation Accuracy: 67.47%\n",
      "Train Accuracy: 87.65%\n",
      "Validation Accuracy: 58.90%\n",
      "Train Accuracy: 89.49%\n",
      "Validation Accuracy: 65.58%\n",
      "Train Accuracy: 90.48%\n",
      "Validation Accuracy: 66.78%\n",
      "Train Accuracy: 94.51%\n",
      "Validation Accuracy: 66.10%\n",
      "Train Accuracy: 90.14%\n",
      "Validation Accuracy: 62.50%\n",
      "Train Accuracy: 88.89%\n",
      "Validation Accuracy: 62.50%\n",
      "Train Accuracy: 97.43%\n",
      "Validation Accuracy: 70.72%\n",
      "Train Accuracy: 94.90%\n",
      "Validation Accuracy: 66.95%\n",
      "Train Accuracy: 92.07%\n",
      "Validation Accuracy: 65.07%\n",
      "Train Accuracy: 95.33%\n",
      "Validation Accuracy: 70.55%\n",
      "Train Accuracy: 94.77%\n",
      "Validation Accuracy: 70.03%\n",
      "Train Accuracy: 93.83%\n",
      "Validation Accuracy: 67.81%\n",
      "Train Accuracy: 93.78%\n",
      "Validation Accuracy: 69.52%\n",
      "Train Accuracy: 85.89%\n",
      "Validation Accuracy: 59.25%\n",
      "Train Accuracy: 86.15%\n",
      "Validation Accuracy: 58.22%\n",
      "Train Accuracy: 94.08%\n",
      "Validation Accuracy: 65.58%\n",
      "Train Accuracy: 84.43%\n",
      "Validation Accuracy: 59.08%\n",
      "Train Accuracy: 97.13%\n",
      "Validation Accuracy: 71.06%\n",
      "Train Accuracy: 94.98%\n",
      "Validation Accuracy: 67.98%\n",
      "Train Accuracy: 89.28%\n",
      "Validation Accuracy: 65.07%\n",
      "Train Accuracy: 90.61%\n",
      "Validation Accuracy: 61.99%\n",
      "Train Accuracy: 94.60%\n",
      "Validation Accuracy: 68.84%\n",
      "Train Accuracy: 80.27%\n",
      "Validation Accuracy: 52.57%\n",
      "Train Accuracy: 88.42%\n",
      "Validation Accuracy: 59.42%\n",
      "Train Accuracy: 89.11%\n",
      "Validation Accuracy: 61.64%\n",
      "Train Accuracy: 96.44%\n",
      "Validation Accuracy: 69.69%\n",
      "Train Accuracy: 92.28%\n",
      "Validation Accuracy: 66.44%\n",
      "Train Accuracy: 83.58%\n",
      "Validation Accuracy: 57.02%\n",
      "Train Accuracy: 97.21%\n",
      "Validation Accuracy: 70.03%\n",
      "Train Accuracy: 94.51%\n",
      "Validation Accuracy: 69.35%\n",
      "Train Accuracy: 86.23%\n",
      "Validation Accuracy: 59.76%\n",
      "Train Accuracy: 77.06%\n",
      "Validation Accuracy: 53.42%\n",
      "Train Accuracy: 91.60%\n",
      "Validation Accuracy: 62.50%\n",
      "Train Accuracy: 88.64%\n",
      "Validation Accuracy: 59.93%\n",
      "Train Accuracy: 92.32%\n",
      "Validation Accuracy: 67.47%\n",
      "Train Accuracy: 91.42%\n",
      "Validation Accuracy: 69.35%\n",
      "Train Accuracy: 92.92%\n",
      "Validation Accuracy: 62.67%\n",
      "Train Accuracy: 96.70%\n",
      "Validation Accuracy: 71.06%\n",
      "Train Accuracy: 85.03%\n",
      "Validation Accuracy: 57.02%\n",
      "Train Accuracy: 97.81%\n",
      "Validation Accuracy: 69.52%\n",
      "Train Accuracy: 92.62%\n",
      "Validation Accuracy: 63.87%\n",
      "Train Accuracy: 94.73%\n",
      "Validation Accuracy: 69.35%\n",
      "Train Accuracy: 96.01%\n",
      "Validation Accuracy: 69.35%\n",
      "Train Accuracy: 82.98%\n",
      "Validation Accuracy: 58.56%\n",
      "Train Accuracy: 94.17%\n",
      "Validation Accuracy: 64.04%\n",
      "Train Accuracy: 94.98%\n",
      "Validation Accuracy: 69.69%\n",
      "Train Accuracy: 90.18%\n",
      "Validation Accuracy: 63.70%\n",
      "Train Accuracy: 94.90%\n",
      "Validation Accuracy: 68.66%\n",
      "Train Accuracy: 98.03%\n",
      "Validation Accuracy: 69.52%\n",
      "Train Accuracy: 92.11%\n",
      "Validation Accuracy: 65.24%\n",
      "Train Accuracy: 87.99%\n",
      "Validation Accuracy: 58.05%\n",
      "Train Accuracy: 97.47%\n",
      "Validation Accuracy: 70.89%\n",
      "Train Accuracy: 91.98%\n",
      "Validation Accuracy: 64.21%\n",
      "Train Accuracy: 93.83%\n",
      "Validation Accuracy: 67.47%\n",
      "Train Accuracy: 84.26%\n",
      "Validation Accuracy: 58.39%\n",
      "Train Accuracy: 97.13%\n",
      "Validation Accuracy: 69.01%\n",
      "Train Accuracy: 97.64%\n",
      "Validation Accuracy: 68.66%\n",
      "Train Accuracy: 89.75%\n",
      "Validation Accuracy: 64.55%\n",
      "Train Accuracy: 96.31%\n",
      "Validation Accuracy: 69.52%\n",
      "Train Accuracy: 86.88%\n",
      "Validation Accuracy: 60.45%\n",
      "Train Accuracy: 95.80%\n",
      "Validation Accuracy: 68.66%\n",
      "Train Accuracy: 93.87%\n",
      "Validation Accuracy: 68.15%\n",
      "Train Accuracy: 90.48%\n",
      "Validation Accuracy: 60.45%\n",
      "Train Accuracy: 96.05%\n",
      "Validation Accuracy: 65.92%\n",
      "Train Accuracy: 96.44%\n",
      "Validation Accuracy: 67.29%\n",
      "Train Accuracy: 93.87%\n",
      "Validation Accuracy: 67.64%\n",
      "Train Accuracy: 86.66%\n",
      "Validation Accuracy: 60.96%\n",
      "Train Accuracy: 95.24%\n",
      "Validation Accuracy: 64.38%\n",
      "Train Accuracy: 91.30%\n",
      "Validation Accuracy: 65.24%\n",
      "Train Accuracy: 98.71%\n",
      "Validation Accuracy: 71.06%\n",
      "Train Accuracy: 81.00%\n",
      "Validation Accuracy: 53.08%\n",
      "Train Accuracy: 85.42%\n",
      "Validation Accuracy: 58.73%\n",
      "Train Accuracy: 95.80%\n",
      "Validation Accuracy: 65.41%\n",
      "Train Accuracy: 97.51%\n",
      "Validation Accuracy: 68.15%\n",
      "Train Accuracy: 98.07%\n",
      "Validation Accuracy: 70.89%\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    # print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    print(f\"Train Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
